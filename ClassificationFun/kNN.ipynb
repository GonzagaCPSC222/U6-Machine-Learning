{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height(cm)  weight(kg) t-shirt size\n",
      "0         158          58            M\n",
      "1         163          61            M\n",
      "2         165          61            L\n",
      "3         168          66            L\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"shirt_sizes.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to ML\n",
    "* Supervised machine learning: labeled data (i.e. there is an attribute we want to predict for unseen data)\n",
    "    * e.g. kNN (k nearest neighbors) algorithm\n",
    "* Unsupervised machine learning: unlabeled data\n",
    "    * e.g. k-means clustering \n",
    "    \n",
    "## Supervised Machine Learning\n",
    "* Somehow, we need to divide our dataset into a training set and a testing set\n",
    "    * The testing set is how you evaluate your classifier\n",
    "    * The testing set is *different* from your training set\n",
    "* Example\n",
    "    * We have the super small t-shirt sizes dataset\n",
    "        * Two features (AKA attributes)\n",
    "            * height and weight\n",
    "        * One class label (AKA attribute)\n",
    "            * t-shirt size\n",
    "            * This is what we want to predict for unseen instances\n",
    "            * Ex. say we have a new instance, height = 161 and weight = 63\n",
    "            * What should it's t-shirt size be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Algorithm\n",
    "* Find the nearest neighbors in a training set to a test instance (e.g. 161, 63)\n",
    "* Pick the majority class from among the k nearest neighbors\n",
    "    * This is the test instance's predicted class\n",
    "* Need a way to measure \"near\" AKA \"close\"\n",
    "    * 2D: Pythagorean theorem to find the distance between two points\n",
    "    * ND: Distance formula (Euclidean) \n",
    "    * $dist(a, b) = \\sqrt{\\sum_{i = 1}^n(a_i - b_i)^2}$\n",
    "* We need to normalize (AKA scale) our features so that the units don't cause an unanticipated weighting (e.g. height is on a larger scale than weight)\n",
    "    * Use a min-max scaling approach\n",
    "    * For each feature, the min becomes 0 and the max becomes 1\n",
    "    * Subtract the feature mean from each value, then subtract the original range from each value (max - min)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN using scikit learn\n",
    "# X are our feature vectors (instances) minus their class labels\n",
    "# y are our class labels\n",
    "X_train = df.drop(\"t-shirt size\", axis=1) # is for columns\n",
    "y_train = df[\"t-shirt size\"]\n",
    "\n",
    "#print(X_train)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.   ]\n",
      " [0.5   0.375]\n",
      " [0.7   0.375]\n",
      " [1.    1.   ]]\n",
      "[[0.3   0.625]]\n"
     ]
    }
   ],
   "source": [
    "# normalize features to [0, 1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train) # fit_transform(X_train)\n",
    "X_train_normalized = scaler.transform(X_train)\n",
    "print(X_train_normalized)\n",
    "X_test = [161, 63]\n",
    "X_test_normalized = scaler.transform([X_test])\n",
    "print(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: ['M']\n",
      "distances: (array([[0.32015621, 0.47169906, 0.69327123]]), array([[1, 2, 0]]))\n"
     ]
    }
   ],
   "source": [
    "# set up our kNN classifier (to get predictions and distances)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
    "\n",
    "knn_clf.fit(X_train_normalized, y_train)\n",
    "y_predicted = knn_clf.predict(X_test_normalized)\n",
    "print(\"prediction:\", y_predicted)\n",
    "print(\"distances:\", knn_clf.kneighbors(X_test_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some closing thoughts on the kNN algorithm:\n",
    "* What do we do if our features are categorical?\n",
    "    * Simple approach: to convert our string feature values into numeric values\n",
    "        * E.g. `from sklearn.preprocessing import LabelEncoder`\n",
    "    * Advanced approach: define your own distance metric for the categorical feature\n",
    "        * E.g. $dist(v_1, v_2) = 0$ if $v_1 == v_2$, 1 otherwise\n",
    "* kNN is not the only classification algorithm\n",
    "    * Decision trees (random forests)\n",
    "    * Naive Bayes\n",
    "    * SVMs (support vector machines)\n",
    "    * Neural networks \n",
    "    * etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Evaluation\n",
    "* For our simple example (trace of kNN), we didn't have the \"ground truth label\" (AKA class) for our test instance\n",
    "    * So how do we know if our classifier was right?\n",
    "* So we need to have a \"test set\" that has ground truth labels for all instances\n",
    "* How do we get a test set?\n",
    "    * Divide a dataset into a \"training set\" and a \"testing set\"\n",
    "* A few ways to do this\n",
    "    * Hold out method\n",
    "    * Random subsampling\n",
    "    * k fold cross validation\n",
    "    * Bootstrap method\n",
    "    \n",
    "### Hold Out Method\n",
    "* \"Hold out\" a certain number or percentage of instances from your dataset to form your test set (the remaining instances form your training set)\n",
    "    * Typically choose a split or a percentage and you typically stratify\n",
    "    * E.g. 2:1 (2/3 in training set and 1/3 in test set)\n",
    "    * E.g. `from sklearn.model_selection import train_test_split` uses a default of 25% for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_csv(\"shirt_sizes_long.csv\")\n",
    "#print(long_df)\n",
    "\n",
    "y = long_df[\"t-shirt size\"]\n",
    "X = long_df.drop(\"t-shirt size\", axis=1)\n",
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58333333 0.3       ]\n",
      " [1.         1.        ]\n",
      " [0.83333333 0.5       ]\n",
      " [0.41666667 0.2       ]\n",
      " [0.58333333 0.7       ]\n",
      " [0.         0.5       ]\n",
      " [0.         0.1       ]\n",
      " [0.41666667 0.6       ]\n",
      " [1.         0.6       ]\n",
      " [0.16666667 0.1       ]\n",
      " [0.16666667 0.2       ]\n",
      " [1.         0.5       ]\n",
      " [0.83333333 0.8       ]]\n",
      "9     L\n",
      "17    L\n",
      "13    L\n",
      "5     M\n",
      "11    L\n",
      "2     M\n",
      "1     M\n",
      "8     L\n",
      "16    L\n",
      "3     M\n",
      "4     M\n",
      "15    L\n",
      "14    L\n",
      "Name: t-shirt size, dtype: object\n",
      "[[0.83333333 0.4       ]\n",
      " [0.41666667 0.3       ]\n",
      " [0.16666667 0.6       ]\n",
      " [0.         0.        ]\n",
      " [0.58333333 0.4       ]]\n",
      "12    L\n",
      "6     M\n",
      "7     L\n",
      "0     M\n",
      "10    L\n",
      "Name: t-shirt size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# hold out\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# task: apply min max scaling to our X (before train test split)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# use random_state for reproducibility\n",
    "# use stratify to ensure a similar distribution of \n",
    "# class labels in your training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'M' 'M' 'M' 'L']\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# task: get predictions for X_test and compare them to y_test\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(y_predicted)\n",
    "# GS note: score needs to be X_test, y_test\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'M' 'L' 'M' 'L']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# do it again with decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_predicted_tree = tree_clf.predict(X_test)\n",
    "print(y_predicted_tree)\n",
    "accuracy_tree = tree_clf.score(X_test, y_test)\n",
    "print(accuracy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Subsampling\n",
    "* Perform the hold out method k times (diff k)\n",
    "* The accuracy is the average accuracy over the k runs\n",
    "\n",
    "### k Fold Cross Validation\n",
    "* Be more intentional about our \"partitions\"\n",
    "* Every instance is testing exactly one time\n",
    "* Divide the dataset into k folds \n",
    "* For each fold:\n",
    "    * Test on the fold\n",
    "    * Train on the remaining folds (folds - fold)\n",
    "* Variants\n",
    "    * LOOCV: leave one out cross validation (k = N)\n",
    "        * Test on each instance one a time\n",
    "        * When you need as much data as possible for training\n",
    "    * Stratified k fold CV\n",
    "* Accuracy is the # of correct classifications over the k iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "[0.6        1.         1.         1.         0.66666667] 0.8533333333333333\n",
      "['M' 'M' 'M' 'M' 'M' 'M' 'L' 'M' 'L' 'M' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L']\n",
      "0.8333333333333334\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "[0.6        0.75       1.         1.         0.66666667] 0.8033333333333333\n",
      "['M' 'M' 'L' 'M' 'M' 'M' 'L' 'M' 'M' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L']\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for model in [clf, tree_clf]:\n",
    "    print(type(model))\n",
    "    accuracies = cross_val_score(model, X, y, cv=5)\n",
    "    print(accuracies, accuracies.mean())\n",
    "    y_predictions = cross_val_predict(model, X, y, cv=5) # GS: look into random_state for this one\n",
    "    print(y_predictions)\n",
    "    # better estimate of accuracy\n",
    "    accuracy = accuracy_score(y, y_predictions)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Method\n",
    "* Like random subsampling, but with replacement\n",
    "* Let D = # of instances in a dataset\n",
    "* Randomly select D instances with replacement\n",
    "    * This dataset is used for training (~63.2% of the original dataset)\n",
    "    * ~36.8% of the instances will not be in the training set (this forms your test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: confusion matrices and warning about accuracy with unbalanced class distributions\n",
    "\n",
    "## Classification Evaluation Metrics\n",
    "* For binary classification...\n",
    "    * Choose one of the class labels to be \"positive\"\n",
    "    * Choose the other class label to be \"negative\"\n",
    "    * P: the # of positive instances in the test set\n",
    "    * N: the # of negative instances in the test set\n",
    "    * TP: the # of positives that are correctly classified as positive\n",
    "    * TN: the # of negatives that are correctly classified as negative\n",
    "    * FP: the # of negatives that are incorrectly classified as positive\n",
    "    * FN: the # of positives that are incorrectly classified as negative\n",
    "* Accuracy: Percent of test instances correctly classified\n",
    "    * Accuracy = $\\frac{TP + TN}{P + N}$\n",
    "    * Warning!! can be skewed if your class distribution is not even\n",
    "* Error rate (1 - accuracy)\n",
    "    * Error rate = $\\frac{FP + FN}{P + N}$\n",
    "* Precision\n",
    "* Recall\n",
    "* F Measure\n",
    "* AUC (area under the ROC curve)...\n",
    "\n",
    "## Regression Evaluation Metrics\n",
    "* Standard error\n",
    "* Mean absolute error\n",
    "* Root mean square error\n",
    "* etc..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
